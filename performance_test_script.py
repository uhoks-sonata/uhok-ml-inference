#!/usr/bin/env python3
"""
scikit-learn vs FAISS ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""

import asyncio
import time
import json
from typing import List, Dict
import numpy as np

# ë²¡í„° ìŠ¤í† ì–´ ì„í¬íŠ¸ (FAISS ì œê±°ë¨)
from store.vector_store import VectorStore
# from store.vector_store_faiss import VectorStoreFAISS  # Python 3.13.5 í˜¸í™˜ì„± ë¬¸ì œë¡œ ì œê±°

async def generate_test_data(num_vectors: int = 1000, dimension: int = 384):
    """í…ŒìŠ¤íŠ¸ìš© ë²¡í„° ë°ì´í„° ìƒì„±"""
    print(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì¤‘: {num_vectors}ê°œ ë²¡í„°, {dimension}ì°¨ì›")
    
    # ëœë¤ ë²¡í„° ìƒì„±
    vectors = np.random.randn(num_vectors, dimension).astype('float32')
    
    # ì •ê·œí™”
    for i in range(num_vectors):
        vectors[i] = vectors[i] / np.linalg.norm(vectors[i])
    
    # ë ˆì‹œí”¼ ID ìƒì„±
    recipe_ids = list(range(1, num_vectors + 1))
    
    return recipe_ids, vectors

async def test_scikit_learn(recipe_ids: List[int], vectors: np.ndarray, queries: List[str], top_k: int = 25):
    """scikit-learn ë²¡í„° ìŠ¤í† ì–´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== scikit-learn ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ===")
    
    store = VectorStore()
    await store.initialize()
    
    # ë²¡í„° ì¶”ê°€
    start_time = time.time()
    await store.add_vectors(recipe_ids, vectors)
    add_time = time.time() - start_time
    print(f"ë²¡í„° ì¶”ê°€ ì‹œê°„: {add_time:.3f}ì´ˆ")
    
    # ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    search_times = []
    for i, query in enumerate(queries):
        start_time = time.time()
        results = await store.search_similar(query, top_k=top_k)
        search_time = time.time() - start_time
        search_times.append(search_time)
        
        if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ì¶œë ¥
            print(f"  ì¿¼ë¦¬ '{query}': {search_time:.3f}ì´ˆ, ê²°ê³¼ {len(results)}ê°œ")
    
    # í†µê³„ ê³„ì‚°
    avg_search_time = np.mean(search_times)
    min_search_time = np.min(search_times)
    max_search_time = np.max(search_times)
    p95_search_time = np.percentile(search_times, 95)
    
    print(f"ê²€ìƒ‰ ì„±ëŠ¥ í†µê³„:")
    print(f"  í‰ê· : {avg_search_time:.3f}ì´ˆ")
    print(f"  ìµœì†Œ: {min_search_time:.3f}ì´ˆ")
    print(f"  ìµœëŒ€: {max_search_time:.3f}ì´ˆ")
    print(f"  P95: {p95_search_time:.3f}ì´ˆ")
    
    await store.cleanup()
    
    return {
        "add_time": add_time,
        "search_times": search_times,
        "avg_search_time": avg_search_time,
        "min_search_time": min_search_time,
        "max_search_time": max_search_time,
        "p95_search_time": p95_search_time
    }

async def test_faiss(recipe_ids: List[int], vectors: np.ndarray, queries: List[str], top_k: int = 25):
    """FAISS ë²¡í„° ìŠ¤í† ì–´ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n=== FAISS ë²¡í„° ìŠ¤í† ì–´ í…ŒìŠ¤íŠ¸ ===")
    
    store = VectorStoreFAISS()
    await store.initialize()
    
    # ë²¡í„° ì¶”ê°€
    start_time = time.time()
    await store.add_vectors(recipe_ids, vectors)
    add_time = time.time() - start_time
    print(f"ë²¡í„° ì¶”ê°€ ì‹œê°„: {add_time:.3f}ì´ˆ")
    
    # ê²€ìƒ‰ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
    search_times = []
    for i, query in enumerate(queries):
        start_time = time.time()
        results = await store.search_similar(query, top_k=top_k)
        search_time = time.time() - start_time
        search_times.append(search_time)
        
        if i < 3:  # ì²˜ìŒ 3ê°œë§Œ ìƒì„¸ ì¶œë ¥
            print(f"  ì¿¼ë¦¬ '{query}': {search_time:.3f}ì´ˆ, ê²°ê³¼ {len(results)}ê°œ")
    
    # í†µê³„ ê³„ì‚°
    avg_search_time = np.mean(search_times)
    min_search_time = np.min(search_times)
    max_search_time = np.max(search_times)
    p95_search_time = np.percentile(search_times, 95)
    
    print(f"ê²€ìƒ‰ ì„±ëŠ¥ í†µê³„:")
    print(f"  í‰ê· : {avg_search_time:.3f}ì´ˆ")
    print(f"  ìµœì†Œ: {min_search_time:.3f}ì´ˆ")
    print(f"  ìµœëŒ€: {max_search_time:.3f}ì´ˆ")
    print(f"  P95: {p95_search_time:.3f}ì´ˆ")
    
    await store.cleanup()
    
    return {
        "add_time": add_time,
        "search_times": search_times,
        "avg_search_time": avg_search_time,
        "min_search_time": min_search_time,
        "max_search_time": max_search_time,
        "p95_search_time": p95_search_time
    }

async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ scikit-learn vs FAISS ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # í…ŒìŠ¤íŠ¸ íŒŒë¼ë¯¸í„°
    num_vectors = 1000
    dimension = 384
    num_queries = 20
    top_k = 25
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    recipe_ids, vectors = await generate_test_data(num_vectors, dimension)
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬ ìƒì„±
    test_queries = [
        "ê¹€ì¹˜ì°Œê°œ", "ëœì¥ì°Œê°œ", "ìˆœë‘ë¶€ì°Œê°œ", "ë¶€ëŒ€ì°Œê°œ",
        "ì œìœ¡ë³¶ìŒ", "ë‹­ë³¶ìŒíƒ•", "ë¼ì§€ê³ ê¸°ë³¶ìŒ", "ì†Œê³ ê¸°ë³¶ìŒ",
        "ê¹€ë°¥", "ë¼ë©´", "ë¹„ë¹”ë°¥", "ë®ë°¥",
        "ìŠ¤í…Œì´í¬", "íŒŒìŠ¤íƒ€", "í”¼ì", "í–„ë²„ê±°",
        "ìƒëŸ¬ë“œ", "ìŠ¤í”„", "ìŠ¤íŠœ", "ì¹´ë ˆ"
    ][:num_queries]
    
    print(f"í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: {len(test_queries)}ê°œ")
    
    # scikit-learn í…ŒìŠ¤íŠ¸
    scikit_results = await test_scikit_learn(recipe_ids, vectors, test_queries, top_k)
    
    # FAISS í…ŒìŠ¤íŠ¸ (ì œê±°ë¨)
    # faiss_results = await test_faiss(recipe_ids, vectors, test_queries, top_k)
    
    # ì„±ëŠ¥ ë¶„ì„ (scikit-learnë§Œ)
    print("\n" + "="*50)
    print("ğŸ“Š scikit-learn ì„±ëŠ¥ ê²°ê³¼")
    print("="*50)
    
    print(f"ë²¡í„° ì¶”ê°€ ì‹œê°„: {scikit_results['add_time']:.3f}ì´ˆ")
    print(f"ê²€ìƒ‰ ì‹œê°„ (í‰ê· ): {scikit_results['avg_search_time']:.3f}ì´ˆ")
    print(f"ê²€ìƒ‰ ì‹œê°„ (P95): {scikit_results['p95_search_time']:.3f}ì´ˆ")
    
    print(f"\nâœ… scikit-learn ì„±ëŠ¥ ì¸¡ì • ì™„ë£Œ!")
    print("   FAISSëŠ” Python 3.13.5 í˜¸í™˜ì„± ë¬¸ì œë¡œ ì œê±°ë¨")
    
    # ê²°ê³¼ ì €ì¥
    results = {
        "test_config": {
            "num_vectors": num_vectors,
            "dimension": dimension,
            "num_queries": num_queries,
            "top_k": top_k
        },
        "scikit_learn": scikit_results,
        "faiss": {
            "status": "removed",
            "message": "Python 3.13.5 í˜¸í™˜ì„± ë¬¸ì œë¡œ ì œê±°ë¨"
        },
        "comparison": {
            "recommendation": "scikit-learn",
            "note": "FAISS ì œê±°ë¡œ scikit-learnë§Œ ì‚¬ìš©"
        },
        "timestamp": time.time()
    }
    
    # JSON íŒŒì¼ë¡œ ì €ì¥
    with open("performance_test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ ê²°ê³¼ê°€ 'performance_test_results.json' íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    asyncio.run(main())
